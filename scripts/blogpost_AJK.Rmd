---
title: "War by the neighbor through the lenses of Hungarian news outlets"
author: "Adam Jozsef Kovacs"
date: "5/11/2022"
output: html_document
---

```{r set chunk options, include=FALSE}
#setting chunk options
knitr::opts_chunk$set(message = FALSE, warning = FALSE, echo = TRUE, eval = TRUE)
```

## Introduction 

Since Russian troops entered the territory of Ukraine and consequently started a war on the 24th February, 2022, thousands of civilians lost their lives and millions were forced to flee the country. The goal of this blogpost is to grasp interesting patterns in the coverage of the war through an in-depth quantitative text analysis of all articles written on the matter by four pro-government Hungarian news portals. To this end, using web scraping, the texts of more than 2000 articles were collected. 

The main research question of the project is what the communication of these mediums looked like before and after April 3rd 2022, when the Hungarian elections were held and around which time the news about the Bucha massacre became public. My impression dictates the main hypothesis of the post, which is that there has been a change in the coverage. I feel that it focuses much less on the humanitarian aid, and how the Hungarians are pacifists and much more on the painful consequences and how we have to be cautious with breaking all ties with the Russians as we are so dependent on their oil and gas. 

All artifacts of this project including the R script used for scraping the articles can be found in [THIS](https://github.com/kovaad/DS3_project) github repository while the data is uploaded in [THIS](https://drive.google.com/drive/folders/1cMQixfuBkXMLztMrB60vyCPrYCxUBCO3?usp=sharing) Google Drive folder as it was too large to put on github. After downloading it, please put it in the data folder to make the code reproducible.

```{r read in, echo = FALSE}
#load packages
if (!require("pacman")) {
  install.packages("pacman")
}
pacman::p_load(dplyr,tidyverse, lubridate, tidytext, ggplot2, mediumr,quanteda,quanteda.textstats, pbapply, ggwordcloud, topicmodels, widyr, igraph, ggraph)

#check out custom theme
source("theme_adam.R")
```

## Data collection and descriptives

For the data collection, I decided to scrape not only one, but four news outlets coverage on the war. During this process, I first scraped all the titles, the dates (day-month-year) on which the articles were written (this had to be standardized) and the links. Then I went through all these links and scraped the actual content (body) of the articles and merged it back to the dataframe. After binding together all the articles, I read it in for the analysis and created an additional dummy variable that signals whether the article was written before or after 3rd April, 2022. For the justification of this date as a milestone refer back to the introduction. 

```{r initial cleaning, echo=FALSE}
df <- read_csv("../data/full_df_correct.csv")

df <- df |> 
  mutate(
    label = ifelse(dates < ymd("2022-4-3"), "before", "after") 
  ) |> 
  rename(text = body)
```

Next, I tokenized all the articles and calculate how many tokens each article consists of. I append this information back to the main dataframe and remove all articles that have less than 10 tokens as they are very unlikely to contain any interesting results to my analysis. 

```{r tokenize and count, echo=FALSE}
tokens <- df |> 
  unnest_tokens(word, text)

tok_count <- tokens |> 
  group_by(dates,links) |> 
  summarise( 
    sum_tokens = n()
  )

df <- left_join(df, tok_count[, names(tok_count) != "dates"], by = "links")

df <- subset(df, !(sum_tokens <= 10))
```

The first descriptive plot depicts the number of articles by news portal. As we can see the majority of the articles are from [magyar nemzet](https://magyarnemzet.hu), namely 1348. In their case, these are all the articles with the tag #warinukraine in Hungarian. This is followed by [mandiner](https://mandiner.hu) with 537 articles, where the tag was #Russian-Ukranianwar in Hungarian. The third source is [szoljon](https://www.szoljon.hu), which is the regional news portal for JÃ¡sz-Nagykun-Szolnok county. It is well-known that all the regional news portal are owned by the same pro-government consortium, so it was chosen to represent that segment of the media. In their case all the articles with the tag #ukraine were pulled from around the start of the Russian invasion. Finally, the fourth news portal is [pesti sracok](https://pestisracok.hu), which is also a pro-government, more radical news portal, where again all articles with the tag #ukraine were collected. 

```{r portal count, include = FALSE}
#create chart of number of articles by news portal
count_by_portal <- df |> group_by(name) |> summarise(count = n()) |> arrange(desc(count))

ggplot(count_by_portal, aes(reorder(name,-count), count)) +
  geom_bar(stat = "identity") +
  labs(
    y = "Number of articles",
    x = NULL
  ) +
  geom_text(data=count_by_portal,aes(label=count,y=count),vjust=-0.5) +
  theme_adam()

ggsave("../images/count_by_portal.png")

```

Next, I was also curious about the time dimension of my data, both the number of articles that were written on these portals and the length of them. First, I visualize the number of articles appeared. The date of appearence of the articles in the data range from 24th January to 1st May (the date of scraping). As we can see on the figure, there are very few articles before the start of war. This is attributable to the fact that, as described earlier, for the two portals with the most articles in the data, the tags searched for when scraping concerned the war specifically so it is logical that it does not have articles before the invasion. For the other two portals, a few articles are included that were written when the Russian troops were only getting ready on the border. 

After the war started, obviously there was a very high demand for latest news on the events and the number of articles in the days afterwards reachd higher than 80 articles a day. As time passed, however, the coverage on the events started to decrease though with high volatility, indicating that on days when some military operation is taking place, the number of articles still tend to increase significantly. 

After the designated events of 3rd April, there was a smaller spike reaching 40 articles a day, but in general, the number of articles became roughly constant at around 20 articles a day. 

```{r number of articles over time, include = FALSE}
#get number of articles and average length of articles by date
overtime <- tok_count %>%
  group_by(dates) %>% 
  summarise( 
    n_articles = n(),
    avg_tokens = mean(sum_tokens)
  )


#plot number of articles in dataset over time
arrows <- 
  tibble(
    x1 = c(ymd("2022-2-8"), ymd("2022-4-15")),
    x2 =  c(ymd("2022-2-24"),ymd("2022-4-3")),
    y1 = c(55, 45), 
    y2 = c(65, 48)
  )

ggplot(overtime, aes(dates, n_articles)) +
  geom_line() +
  labs(
    y = "Number of articles",
    x = NULL
  ) + 
  geom_vline(xintercept=ymd("2022-2-24"), linetype="dashed", 
             color = "red", size=1) + 
  geom_vline(xintercept=ymd("2022-4-3"), linetype="dashed", 
             color = "red", size=1) +
  ggplot2::annotate("text", x = ymd("2022-2-8"), y = 52, label = "Russian invasion of \n Ukraine") +
  ggplot2::annotate("text", x = ymd("2022-4-19"), y = 48, label = "Elections/\nBucha massacre") +
  geom_curve(
    data = arrows, aes(x = x1, y = y1, xend = x2, yend = y2),
    arrow = arrow(length = unit(0.08, "inch")), size = 0.5,
    color = "gray20", curvature = -0.3) +
  theme_adam()

ggsave("../images/count_over_time.png")

```

Then, I look at the length of articles as well (defined by the average number of tokens in the articles each day). As we can see, ery interestingly, the tendencies are exactly the opposite than that of the number of articles. After the invasion, the articles became longer and longer (there is of course volatility here as well, but still). Right before the elections, the average length of articles reached almost 800 tokens, which is roughly the double of the length of articles when the invasion happened. This is probably attributable to the fact that in the beginning, most of the articles were simple short descriptions of the (military) events. But later on, more analysis of the underlying reasons and consequences appeared on these portals that required longer pieces. Also with the elections approaching, such articles may be more effective in shaping the public's opinion on the matter. 

Then, after the elections, the length of the articles dropped to the level where it was when the war broke out (around 400). This may be due to lower interest due to the lack of relevance in domestic politics or the retrn of more shorter pieces on war events. 

```{r evolution of length of articles, include = FALSE}
#plot of evolution of length of articles
arrows <- 
  tibble(
    x1 = c(ymd("2022-2-3"), ymd("2022-4-23")),
    x2 =  c(ymd("2022-2-24"),ymd("2022-4-3")),
    y1 = c(650, 200), 
    y2 = c(700, 250)
  )

ggplot(overtime, aes(dates, avg_tokens)) +
  geom_line() +
  labs(
    y = "Average length of articles",
    x = NULL
  ) + 
  geom_vline(xintercept=ymd("2022-2-24"), linetype="dashed", 
             color = "red", size=1) + 
  geom_vline(xintercept=ymd("2022-4-3"), linetype="dashed", 
             color = "red", size=1) +
  ggplot2::annotate("text", x = ymd("2022-2-2"), y = 620, label = "Russian invasion of \n Ukraine") +
  ggplot2::annotate("text", x = ymd("2022-4-23"), y = 230, label = "Elections/\nBucha massacre") +
  geom_curve(
    data = arrows, aes(x = x1, y = y1, xend = x2, yend = y2),
    arrow = arrow(length = unit(0.08, "inch")), size = 0.5,
    color = "gray20", curvature = -0.3) +
  theme_adam()

ggsave("../images/length_over_time.png")

```

## Data cleaning

For the data cleaning part, I created a function that does all the necessary steps and can be applied to the raw texts in the dataset. First, it removes all the punctuations and numbers from the texts. This is necessary, because they do not contain any meaningful information for our type of analysis (even numbers, because as they are text in this context, the difference between 5 and 10 is the same as that of 5 and 11). Then, all text is made lower case so that words at the beginning and end of sentences are treated as the same tokens. Next, all whitespaces at the end of the documents and between words are removed. 

After tokenization, two sets of Hungarian stopwords are removed, one is provided by the tidytext package and the other is specifically developed for hungarian texts (on political matters) by a research group at the Hungarian Academy of Sciences: [link](https://github.com/poltextlab/HunMineR). Finally, I remove all tokens that consist of only 3 characters or less as they are most likely text garbage as well. 

After pasting the tokens back together, I assign the cleaned texts to a separate column of my dataframe. 

```{r stops, echo = FALSE}
custom_stopwords <- HunMineR::data_stopwords_extra

tidy_stops <- get_stopwords('hu')[,1]$word
```


```{r data cleaning, echo=TRUE}
cleaner <- function(text) {

  text <- stringr::str_remove_all(string = text, pattern = "[:punct:]") 
  text <- stringr::str_remove_all(string = text, pattern = "[:digit:]") 
  text <- stringr::str_to_lower(text)
  text <- stringr::str_trim(text) 
  text <- stringr::str_squish(text)
  
  tokens <- unlist(strsplit(text, "\\s+"))
  tokens <- tokens[!(tokens %in% tidy_stops)]
  tokens <- tokens[!(tokens %in% custom_stopwords)]
  tokens <- tokens[length(tokens) >= 3]
  
  clean_text <- paste0(tokens, collapse = " ")
  
  return(clean_text)
}

df$clean_text <- pblapply(df$text, cleaner)
```


## Word frequencies

After the preprocessing, the first thing I wanted to look at are the word frequencies of the articles before and after the elections. First of all, it is notable that the frequency scale is different, there are much more words before than after the elections, which is attributable to the sheer difference in the number of articles written as we have seen already before (1661 before, 492 after). Nevertheless, the comparison of most frequent terms is valid (but leaves room for future research when the number of articles evens out). 

Unsurprisingly, the Russia, Russian, Ukraine, Ukrainian words top the charts, but still there are some interesting takeaways. Before the elections, the word Hungarian ("magyar") was the fifth most frequent signalling the importance of the effect of the war on domestic matters. After the elections, on the other hand, the words European and American both became more frequent, so the focus shifted towards more international discussions. The question of whether lemmatization or stemming would not have made sense generally arises from this figure. Firstly, I did not find any good tool for lemmatization of Hungarian text. Secondly, I tried lemmatization, but it decreased the interpretability of the results to me substantially, so I decided to drop it (if I had the focus on e.g. classifying documents using some sort of supervised ML algorithm, it probably would have made sense, but my focus was rather on exploratory research). 

```{r word frequencies, include=FALSE}
#create tidy tokens dataframe using tidytext from tokens before designated date
tokens_before <- df |> 
  filter(label == "before") |> 
  unnest_tokens(word, clean_text)

#count tokens by article
tok_count_before <- tokens_before |> 
  count(word, sort = TRUE) |> 
  top_n(10) |> 
  mutate(group = "before")

#create tidy tokens dataframe using tidytext
tokens_after <- df |> 
  filter(label == "after") |> 
  unnest_tokens(word, clean_text)

#count tokens by article
tok_count_after <- tokens_after |> 
  count(word, sort = TRUE) |> 
  top_n(10) |> 
  mutate(group = "after")

freq <- bind_rows(tok_count_after,tok_count_before)

#before after word frequency
freq %>% 
  ggplot(aes(x = tidytext::reorder_within(x=word, 
                                          by=n, 
                                          within=group), 
             y = n)) +
  geom_point() +
  coord_flip() +
  labs(x = NULL,
       y = "Frequency") +
  facet_wrap(~group, scales = "free") +
  tidytext::scale_x_reordered() +
  theme_adam()

ggsave("../images/word_freq.png",width = 6, height = 4)

```

To not constrain the analysis down to the top 10 words, I also created a wordcloud with the 40 most frequent words respectively. Looking at some of the less frequent words as well, we can see the name of the Ukranian and the Russian presidents popping up. There is also talk about the economy and international matters. 

```{r wordcloud, include=FALSE}
#count tokens by article 2
tok_count_before2 <- tokens_before |> 
  count(word, sort = TRUE) |> 
  top_n(40) |> 
  mutate(group = "before")

#count tokens by article 2
tok_count_after2 <- tokens_after |> 
  count(word, sort = TRUE) |> 
  top_n(40) |> 
  mutate(group = "after")

freq2 <- bind_rows(tok_count_after2,tok_count_before2)

#wordcloud
freq2|> 
  ggplot(aes(label = word, size = n, colour = group)) +
  scale_size_area(max_size = 10) +
  geom_text_wordcloud(show.legend = TRUE) +
  theme_minimal()

ggsave("../images/wordcloud.png")
```


Moving on with more sophisticated analysis on the words of the articles, it is also interesting to look at the unique words in the two categories, the ones that appear to be influential in one type of texts (here before the elections) compared to the other types of texts (articles after the elections). There are multiple approaches for measuring this and though using tf-idf would have also been adequate (please find it in the [github repo](https://github.com/kovaad/DS3_project)), I decided to include here the [keyness metric](https://benjamins.com/catalog/scl.41), which looks at important, characteristic words in the after group compared to that of the other group. To this end, I used the quanteda package, which has a nice implementation of it.  

```{r keyness, include=FALSE}
dfm_grouped <- corpus(df) |> 
  tokens( 
    remove_punct = TRUE, 
    remove_numbers = TRUE 
  ) |> 
  tokens_tolower() |>  
  tokens_select(pattern = tidy_stops,selection = "remove" ) |> 
  tokens_select(pattern = custom_stopwords, selection = "remove") |> 
  dfm() |> 
  quanteda::dfm_group(label)

result_keyness <- dfm_grouped |>  
  quanteda.textstats::textstat_keyness(target = "before")

result_keyness |> 
  quanteda.textplots::textplot_keyness(color = c("#484848", "#D0D0D0")) +
  xlim(c(-220, 200)) +
  theme(legend.position = c(0.9,0.1))

ggsave("../images/keyness.png", width = 7, height = 7)
```

Looking at the results, we can see that before the elections, the most important words were primarily concerning domestic politics i.e. Hungarian, border, leftist, Orban (the PM of Hungary) etc. But after the elections, and more importantly in this case, after the Bucha massacre, the most important words compared to the articles beforehand became words associated with Bucha (bucsÃ¡ban, bucsai) and Mariupol (azovsztal) where heavy war events are ongoing. Also, the French elections gained publicity in light of the war as well with candidate Marine Le Pen's name also popping up. 

## Sentiment analysis

Next, I turn to the analysis of the sentiment of the articles. I use the Hungarian sentiment dictionary that can be found [here](http://opendata.hu/hu/dataset/hungarian-sentiment-lexicon). I am interested in two things, first of all just to get a general sense of what drives the sentiment of these articles, I look at the words that contributed most to the values that we will look at. To this end, I visualize the 10 most frequently occuring positive or negative words. 

```{r sentiment words, include=FALSE}
positive_words <- read_csv("../data/PrecoSenti/PrecoPos.csv") |>
  mutate(sentiment=1)

negative_words <- read_csv("../data/PrecoSenti/PrecoNeg.csv") |>
  mutate(sentiment=-1)

hungarian_sentiment <- rbind(positive_words, negative_words)

sent_tokens <- tokens |> 
  inner_join(hungarian_sentiment)

sent_tokens |>
  count(word, sentiment, sort = TRUE) |>
  ungroup()|>
  mutate(word = reorder(word, n)) |>
  top_n(10) |>
  ggplot(aes(word, n, fill = sentiment)) + 
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") + 
  labs(y = "Contribution to sentiment", x = NULL) + 
  coord_flip()

ggsave("../images/sentiment_contribution.png")
```

As we can see from the top 10 words with sentiment, 6 are negative and 4 are positive. Two versions of war lead the line on the negative side, which is rather unsurprising, conflict and fear follow, while attack and refugee also made the cut on the negative side. In terms of words with rather positive sentiment, important leads the line (not sure how positive it is, but ok). Two variations of good and peace are among the frequent ones as well. 

Coming back to the research question of this study, I also look at the evolution of sentiment over time. To this end, I group my data by date and sum up all the sentiment values of the articles where all negative words are counted as -1 and all the positive ones are counted as 1 (neutrals as 0). Obviously this measure is somewhat biased in the sense that we do not control with the length and count of articles, but the idea behind was that if there are more articles being written that are negative that just deepens the argument for the characterization of that period with the corresponding sentiment score. 

```{r sentiment over time, include=FALSE}

df_sent_time <- sent_tokens |> 
  group_by(dates) |> 
  summarise( 
    score = sum(sentiment)
  )

arrows <- 
  tibble(
    x1 = c(ymd("2022-2-3"), ymd("2022-4-23")),
    x2 =  c(ymd("2022-2-24"),ymd("2022-4-3")),
    y1 = c(-50, -100), 
    y2 = c(-50, -100)
  )

ggplot(df_sent_time, aes(dates, score)) +
  geom_line() +
  labs(
    y = "Sentiment score",
    x = NULL
  ) + 
  geom_vline(xintercept=ymd("2022-2-24"), linetype="dashed", 
             color = "red", size=1) + 
  geom_vline(xintercept=ymd("2022-4-3"), linetype="dashed", 
             color = "red", size=1) +
  ggplot2::annotate("text", x = ymd("2022-2-1"), y = -60, label = "Russian invasion of \n Ukraine") +
  ggplot2::annotate("text", x = ymd("2022-4-23"), y = -90, label = "Elections/\nBucha massacre") +
  geom_curve(
    data = arrows, aes(x = x1, y = y1, xend = x2, yend = y2),
    arrow = arrow(length = unit(0.08, "inch")), size = 0.5,
    color = "gray20", curvature = -0.3) +
  theme_adam()

ggsave("../images/sentiment_evolution.png")
```


Looking at the resulting chart, we can see that before the 24th of February, those couple of articles were rather neutral, it shows really that the war was uncertain to the last minute. The overall sentiment score of the articles then plummeted when the Russian troops actually crossed the Ukrainian border. Though the sentiment score is pretty volatile it remained negative in total in the coming months. With the elections approaching and time passing by, some slight positive trend can be detected, and at the day of the elections, apparently even the news about the war got an unexpected boost of morale. But as further news on the events in Bucha and Mariupol started to appear in the media, the sentiment remained in this slightly negative tone of net roughly 25 negative words. 

## Topic modelling

In the next part of this analysis, I decided to also look for topics that appeared in the articles before and after the general elections were held in Hungary. In order to accomplish this, the first task was to reach the required input format for the Latent Dirichlet Allocation implementation in R, which is a document term matrix. It has all the term frequencies by article. After it was done, I trained the model looking for 9 topics, which I deemed adequate to the size of the data. I look at the top 5 terms in each topic, and een though as it is an unsupervised machine learning model i.e. it has no labels, I will try to grasp what some of the topics may represent and why those terms tend to co-occure that are in them. 

```{r topics before, include = FALSE}
word_count_before <- tokens_before |>
  count(links,word, sort = TRUE) |>
  ungroup()

dtm_before <- word_count_before |>
  cast_dtm(links, word, n)

word_count_after <- tokens_after |>
  count(links,word, sort = TRUE) |>
  ungroup()

dtm_after <- word_count_after |>
  cast_dtm(links, word, n)

gibbs_before <- LDA(dtm_before, k = 9, method = "Gibbs", control = list(seed = 1234))

gibbs_after <- LDA(dtm_after, k = 9, method = "Gibbs", control = list(seed = 1234))

topics_before <- tidy(gibbs_before, matrix = "beta") |>
  mutate(label = "before")

topics_after <- tidy(gibbs_after, matrix = "beta") |>
  mutate(label = "after")

lda_gibbs <- bind_rows(topics_before, topics_after)

top_terms_gibbs <- lda_gibbs |>
  group_by(label, topic) |>
  top_n(5, beta) |>
  top_n(5, term) |>
  ungroup() |>
  arrange(topic, -beta)

top_terms_gibbs |>
  filter(label == "before") |>
  ggplot(aes(reorder_within(term, beta, topic), beta)) +
  geom_col(show.legend = FALSE) +
  theme(panel.spacing = unit(4, "lines")) +
  coord_flip() +
  labs(
    title = ,
    x = NULL,
    y = NULL
  ) +
  tidytext::scale_x_reordered() +
  facet_wrap(~topic, scales = "free") + theme_adam()

ggsave("../images/topics_before.png")

```

Looking at the topics that emerge before the elections, we can identify several interesting ones. Topic 1 has words about domestic politics, both candidates names are in it (orbÃ¡n and pÃ©ter), Hunary and Hungarian also appear. Topic 2 simply concerns words about the war, while topic 3 has words about the economy and sanctions. Topic 5 is about the refugees, while topic 7 shows that there are also a couple of articles that were written in English, which LDA separated nicely. Finally, among the intereesting ones, topic 8 is concerned with the attitude of the United States, the name of the president also appears. 

```{r topics after, include = FALSE}
top_terms_gibbs |>
  filter(label == "after") |>
  ggplot(aes(reorder_within(term, beta, topic), beta)) +
  geom_col(show.legend = FALSE) +
  theme(panel.spacing = unit(4, "lines")) +
  coord_flip() +
  labs(
    title = ,
    x = NULL,
    y = NULL
  ) +
  tidytext::scale_x_reordered() +
  facet_wrap(~topic, scales = "free") + theme_adam()

ggsave("../images/topics_after.png")
```

Regarding the topics that emerge from the tokens of the articles written after the elections, the first topic on domestic politics remains well separated, so is the topic on refugees, whiich is the second one this time. There is a separate topic on EU matters (topic 5) and also on economic stuff in topic 7. The English written articles are again a separate topic, while in the last one the presidents are in focus (Zelenszkij and Putin). 

Overall, the topics remained fairly similar, there seems to be a bit more focus on international matters than beforehands. 

## Co-occurences

Finally, as we have not even utilized that part of the data yet, it is also worth to analyze the titles of the articles. To this end, and to use another tool for text mining, I build a co-occurence network of words and visualize it using the [igaph](https://igraph.org) package. Since titles are fairly short and so it would not make much sense to separate the data into articles before and after the elections, I decided to simply look at the co-occurence of words in all the titles in my dataframe. 

```{r co-occur, include=FALSE}
df$clean_titles <- pblapply(df$titles, cleaner)

title_tokens <- df |> 
  unnest_tokens(word, clean_titles)

title_word_pairs <- title_tokens |> 
  pairwise_count(word, links, sort = TRUE, upper = FALSE)

set.seed(1234)
title_word_pairs |> 
  filter(n >= 8) |> 
  graph_from_data_frame() |> 
  ggraph(layout = "fr") +
  geom_edge_link(aes(edge_alpha = n, edge_width = n), edge_colour = "cyan4") +
  geom_node_point(size = 5) +
  geom_node_text(aes(label = name), repel = TRUE, 
                 point.padding = unit(0.2, "lines")) +
  theme_void()

ggsave("../images/title_co_occurence.png")
```

As we can see there are several small pairs of words that occur together (at least 8 times, which was my chosen limit). Most of these refer to names e.g. Joe Biden, Pope Francis or Von der Leyen. The rest of the commonly co-occuring words form a hub, where the 4 words that are in the center mean together that war happened in Ukraine over the night, so probably all those articles on the 24th after the Russian invasion started with their title containing all these words together. What is further interesting that even in the titles, one of the main slogens of the ruling party in the run-up to the elections was that the opposition would send troops and ammunition to Ukraine and these words (katonÃ¡kat, fegyvereket, ukrajnÃ¡ba) indeed co-occure a lot with the name of the PM candidate of the united opposition (MÃ¡rki-Zay).The rest of the co-occurences center around Russian, Ukrainian troops, piece, Hungary etc. that I expected as well.  

## Conclusion

To sum up, in this research I investigated the coverage of the Russian-Ukranian war through the lenses of four pro-government Hungarian news portals and wanted to get a handle on possible differences in communication before and after the general elections and the time around which the Bucha massacre became public. To this end, I used several text mining tools ranging from word frequencies and keyness to sentiment analysis and topic modelling and the co-occurence of words in titles. Findings suggest that there was indeed a change in the length and frequency of articles (former increased, latter decreased). The sentiment also changed and stabilized at a higher, but still negative level. In terms of topics, there were no major changes, but the ones present were separated nicely with the LDA algorithm. Finally, in the titles, one of the main campaign messages of the ruling party appeared. 


